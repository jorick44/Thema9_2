---
title: "EDA Jorick Baron"
author: "Jorick Baron"
output: pdf_document
---

```{r setup, message=FALSE}
library(tidyr)
library(dplyr)
library(ggplot2)
library(gridExtra)
library(knitr)
library(kableExtra)
library(e1071) 
library(foreign)
```

# Start of research

## Research question

How accurate can a model be trained to detect the difficult to diagnose pancreatic cancer utilising a patient's urine sample?

## Codebook

In this EDA we will explore the data downloaded from [[here]{.underline}](https://www.kaggle.com/johnjdavisiv/urinary-biomarkers-for-pancreatic-cancer). For future reference we will describe the data in the codebook below.

```{r codebook, echo=TRUE}
codebook <- read.delim("Data/codebook.csv", sep = ",")
kable(codebook, caption = "Codebook", align = "lcccr", booktabs = T) %>%
  kable_styling(latex_options = c("scale_down"))
```

\pagebreak

## Loading data

First we will load in the data and to check if it has loaded in properly we look at the structure of the loaded data.

```{r structure, echo=TRUE}
data <- read.table(file="Data/source/Debernardi et al 2020 data.csv", sep = ",",
                   header = T, na.strings = "")
data$has_cancer <- ifelse(data$diagnosis == 3, 1, 0)
data$has_cancer <- factor(data$has_cancer)
data$sex <- factor(data$sex)
data <- subset(data, select = c(-diagnosis))

str(data)
```

Thus far it seems to have loaded correctly.

We will also check the first few records to maybe catch some possible errors.

```{r head}
kable(head(data), caption = "The first records of the loaded data", booktabs = T,
      align = "lccccccccccccr") %>%
  kable_styling(latex_options = c("scale_down"))
```

The data seems to have quite a few NAs, reading further into the description most NAs would be expected i.e. no stage if there is no cancer thus an NA.

## NAs

The NAs in columns "plasma_CA19_9" and "REG1A" are supposed to be there because not every patient had been fully tested:\
"REG1A ... Only assessed in 306 patients", "plasma_CA19_9 ... Only assessed in 350 patients" see Debernardi et al 2020 documentation.csv in the source files.\
However to make sure everything is correct these numbers will be tested.

```{r check NA biomarkers}
n_plasma_CA19_9 <- nrow(data) - sum(is.na(data$plasma_CA19_9))
n_REG1A <- nrow(data) - sum(is.na(data$REG1A))
paste("REG1A:", n_REG1A, "plasma_CA19_9:", n_plasma_CA19_9)
```

These numbers are correct.

Are there more NAs?

```{r final NA check}
sum(is.na(data[, c(1:5, 9:12)]))
```

0 NAs remaining.

# Data exploration

## Distribution

Class label checking the different diagnoses should be in similar number to each has_cancer.

```{r}
paste("Amount of patients without cancer:", nrow(subset(data, has_cancer == 0)))
paste("Amount of patients with cancer:", nrow(subset(data, has_cancer == 1)))
```

These are quite balanced and should not influence statistics.

Let's look at a summary of the data for a quick overview of the distributions.

```{r sumaries}
summary(data[,c(4, 9:14)])
```

Much of the data seems to be imbalanced with outliers.

Now let's take a closer look at the data itself using box-plots.

```{r boxplots ungrouped, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="boxplots of diferent values"}
p1<- ggplot(data=data)+
  geom_boxplot(mapping = aes(x = "",
                            y = age))+
  ylab("age in years") + 
  xlab(NULL)

p2<- ggplot(data=data)+
  geom_boxplot(mapping = aes(x = "",
                            y = creatinine))+
  ylab("creatinine in mg/ml") + 
  xlab(NULL)

p3<- ggplot(data=data)+
  geom_boxplot(mapping = aes(x = "",
                            y = LYVE1))+
  ylab("LYVE1 in ng/ml") + 
  xlab(NULL)+
  ylim(0,17)

p4<- ggplot(data=data)+
  geom_boxplot(mapping = aes(x = "",
                            y = REG1B))+
  ylab("REG1B in ng/ml") + 
  xlab(NULL)+
  ylim(0,600)

p5<- ggplot(data=data)+
  geom_boxplot(mapping = aes(x = "",
                            y = TFF1))+
  ylab("TFF1 in ng/ml") + 
  xlab(NULL)+
  ylim(0,5000)

p6<- ggplot(data=data)+
  geom_boxplot(mapping = aes(x = "",
                            y = REG1A))+
  ylab("REG1A in ng/ml") + 
  xlab(NULL) +
  ylim(0,5000)

grid.arrange(p1, p2, p3, p4, p5, p6, nrow = 2)
```

There are many outliers to take a good look at the whiskers y-limits are in place. Still it's a lot, maybe adding another dimension can correct this.

To add this extra dimension let's look at the difference in diagnoses. To properly do this we will also assign levels to the has_cancer column in the dataframe.

```{r boxplot grouped, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, fig.cap="boxplots with added dimension (has_cancer)"}
my_colours <- c("cyan3" ,"coral2")

gp1 <- ggplot(data = data)+
  geom_boxplot(mapping = aes(x = has_cancer,
                            y = age,
                            group=has_cancer,
                            fill=has_cancer))+
    scale_x_discrete(labels=c("control",
                            "pancreatic cancer"))+
  scale_fill_manual(values=my_colours)+
  xlab("has_cancer")+
  ylab("age in years")

gp2 <- ggplot(data = data)+
  geom_boxplot(mapping = aes(x = has_cancer,
                            y = creatinine,
                            group=has_cancer,
                            fill=has_cancer))+
    scale_x_discrete(labels=c("control",
                            "pancreatic cancer"))+
  scale_fill_manual(values=my_colours)+
  xlab("has_cancer")+
  ylab("creatinine in mg/ml")

gp3 <- ggplot(data = data)+
  geom_boxplot(mapping = aes(x = has_cancer,
                            y = LYVE1,
                            group=has_cancer,
                            fill=has_cancer))+
    scale_x_discrete(labels=c("control",
                            "pancreatic cancer"))+
  scale_fill_manual(values=my_colours)+
  xlab("has_cancer")+
  ylab("LIVE1 in ng/ml")+
  ylim(0,17)

gp4 <- ggplot(data = data)+
  geom_boxplot(mapping = aes(x = has_cancer,
                            y = REG1B,
                            group=has_cancer,
                            fill=has_cancer))+
    scale_x_discrete(labels=c("control",
                            "pancreatic cancer"))+
  scale_fill_manual(values=my_colours)+
  xlab("has_cancer")+
  ylab("REG1B in ng/ml")+
  ylim(0,600)

gp5 <- ggplot(data = data)+
  geom_boxplot(mapping = aes(x = has_cancer,
                            y = TFF1,
                            group=has_cancer,
                            fill=has_cancer))+
  scale_x_discrete(labels=c("control",
                            "pancreatic cancer"))+
  scale_fill_manual(values=my_colours)+
  xlab("has_cancer")+
  ylab("TFF1 in ng/ml")+
  ylim(0,5000)

gp6 <- ggplot(data = data)+
  geom_boxplot(mapping = aes(x = has_cancer,
                            y = REG1A,
                            group=has_cancer,
                            fill=has_cancer))+
    scale_x_discrete(labels=c("control",
                            "pancreatic cancer"))+
  scale_fill_manual(values=my_colours)+
  xlab("has_cancer")+
  ylab("REG1A in ng/ml")+
  ylim(0,5000)

grid.arrange(gp1, gp2, gp3, gp4, gp5, gp6, nrow = 2)
```

\newpage

The data still has many outliers but by many columns a pattern does emerge.

## Log transformation

Let's use statistical tests to test the skewness to see how imbalanced the data is.

```{r skewness}
s1 <- skewness(data$age) 
s2 <- skewness(data$creatinine)
s3 <- skewness(data$LYVE1)
s4 <- skewness(data$REG1B)
s5 <- skewness(data$TFF1)
s6 <- skewness(data$REG1A, na.rm = T) 
```

| Variable   | Skewness | Interpretation            |
|------------|----------|---------------------------|
| age        | `r s1`   | Fairly symmetrical        |
| creatinine | `r s2`   | Greatly positively skewed |
| LYVE1      | `r s3`   | Greatly positively skewed |
| REG1B      | `r s4`   | Greatly positively skewed |
| TFF1       | `r s5`   | Greatly positively skewed |
| REG1A      | `r s6`   | Greatly positively skewed |

: Results of skewness test.

Here we see that everything is greatly skewed except age.

A way of dealing with this skewness is to apply a log transformation on the data due to the high positively skewed data.

\newpage

```{r log transformation}
trans <- as.data.frame(log2(data$creatinine))
names(trans) <- "creatinine"
trans$LYVE1 <- log2(data$LYVE1)
trans$REG1B <- log2(data$REG1B)
trans$TFF1 <- log2(data$TFF1)
trans$REG1A <- log2(data$REG1A + 1)
trans$has_cancer <- data$has_cancer
kable(head(trans), caption = "the first few records of the log2 transformed data",
      align = "lccccr", booktabs = T) %>%
  kable_styling(latex_options = c("HOLD_position"))
```

Now having transformed the data lets see how this influences the distribution.

```{r boxplot transformed data, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, fig.cap="boxplots of transformed values"}

tgp1 <- ggplot(data = trans)+
  geom_boxplot(mapping = aes(x = has_cancer,
                            y = creatinine,
                            group=has_cancer,
                            fill=has_cancer))+
    scale_x_discrete(labels=c("control",
                            "pancreatic cancer"))+
  scale_fill_manual(values=my_colours)+
  xlab("has_cancer")+
  ylab("creatinine in mg/ml (log2 transformed)")

tgp2 <- ggplot(data = trans)+
  geom_boxplot(mapping = aes(x = has_cancer,
                            y = LYVE1,
                            group=has_cancer,
                            fill=has_cancer))+
    scale_x_discrete(labels=c("control",
                            "pancreatic cancer"))+
  scale_fill_manual(values=my_colours)+
  xlab("has_cancer")+
  ylab("LIVE1 in ng/ml (log2 transformed)")

tgp3 <- ggplot(data = trans)+
  geom_boxplot(mapping = aes(x = has_cancer,
                            y = REG1B,
                            group=has_cancer,
                            fill=has_cancer))+
    scale_x_discrete(labels=c("control",
                            "pancreatic cancer"))+
  scale_fill_manual(values=my_colours)+
  xlab("has_cancer")+
  ylab("REG1B in ng/ml (log2 transformed)")

tgp4 <- ggplot(data = trans)+
  geom_boxplot(mapping = aes(x = has_cancer,
                            y = TFF1,
                            group=has_cancer,
                            fill=has_cancer))+
  scale_x_discrete(labels=c("control",
                            "pancreatic cancer"))+
  scale_fill_manual(values=my_colours)+
  xlab("has_cancer")+
  ylab("TFF1 in ng/ml (log2 transformed)")

tgp5 <- ggplot(data = trans)+
  geom_boxplot(mapping = aes(x = has_cancer,
                            y = REG1A,
                            group=has_cancer,
                            fill=has_cancer))+
    scale_x_discrete(labels=c("control",
                            "pancreatic cancer"))+
  scale_fill_manual(values=my_colours)+
  xlab("has_cancer")+
  ylab("REG1A in ng/ml (log2 transformed)")

grid.arrange(tgp1, tgp2, tgp3, tgp4, tgp5, nrow = 2)
```

This data looks more normalized than before.

However it's good practice to test normality after transformations.

```{r qqlpots, fig.height=10, fig.width=20, message=FALSE, warning=FALSE, fig.cap="qqplots displaying normalcy"}

swt1 <- shapiro.test(trans$creatinine)
qq1 <- ggplot(trans, aes(sample = creatinine, colour = has_cancer)) +
  stat_qq() +
  stat_qq_line() +
  scale_color_manual(values=my_colours)+
  ggtitle("creatinine")

swt2 <- shapiro.test(trans$LYVE1)
qq2 <- ggplot(trans, aes(sample = LYVE1, colour = has_cancer)) +
  stat_qq() +
  stat_qq_line() +
  scale_color_manual(values=my_colours)+
  ggtitle("LYVE1")

swt3 <- shapiro.test(trans$REG1B)
qq3 <- ggplot(trans, aes(sample = REG1B, colour = has_cancer)) +
  stat_qq() +
  stat_qq_line() +
  scale_color_manual(values=my_colours)+
  ggtitle("REG1B")

swt4 <- shapiro.test(trans$TFF1)
qq4 <- ggplot(trans, aes(sample = TFF1, colour = has_cancer)) +
  stat_qq() +
  stat_qq_line() +
  scale_color_manual(values=my_colours)+
  ggtitle("TFF1")

swt5 <- shapiro.test(trans$REG1A)
qq5 <- ggplot(trans, aes(sample = REG1A, colour = has_cancer)) +
  stat_qq() +
  stat_qq_line() +
  scale_color_manual(values=my_colours)+
  ggtitle("REG1A")

grid.arrange(qq1, qq2, qq3, qq4, qq5, nrow = 2)
```

The data is despite the transformation still not fully normalised however we can still continue but this should be kept this in mind in case of future problems.

| Variable   | p-value          | Interpretation                        |
|------------|------------------|---------------------------------------|
| creatinine | `r swt1$p.value` | this data is not normally distributed |
| LYVE1      | `r swt2$p.value` | this data is not normally distributed |
| REG1B      | `r swt3$p.value` | this data is not normally distributed |
| TFF1       | `r swt4$p.value` | this data is not normally distributed |
| REG1A      | `r swt5$p.value` | this data is not normally distributed |

: Results and interpertation of shapiro wiks test of normalcy

\newpage

## Correlations

Now using the transformed data let's create a new dataframe.

```{r new dataframe}
new_data <- cbind(data[4:5], trans)
new_data$sex <- factor(new_data$sex)
```

Using the new dataframe let's explore if the data is correlated.

```{r heatmap, fig.height=5, fig.width=10, fig.cap="heatmap displaying correlation of values"}
matrix_data <- drop_na(new_data[,c(1, 3:7)])
cor_matrix <- cor(matrix_data)
heatmap(cor_matrix, scale = "none", col = heat.colors(6, rev = T), main = "Heatmap depicting correlations", symm = T, Rowv = NA, Colv = NA)
legend(x="right", legend=c("full","very strong", "strong", "moderate", "weak", "negligible"),fill=heat.colors(6))
```

\newpage

REG1 A and B seem moderately correlated (`r cor_matrix[4,6]`), otherwise no real strong correlation is observed.

Now we also should check if any variable is seemingly influential for the has_cancer so we can see later if the machine learning picks up on this.

```{r t-tests, message=FALSE, warning=FALSE}

t1 <- t.test(new_data$age ~ new_data$has_cancer)
t2 <-t.test(new_data$creatinine ~ new_data$has_cancer)
t3 <-t.test(new_data$LYVE1 ~ new_data$has_cancer)
t4 <-t.test(new_data$REG1B ~ new_data$has_cancer)
t5 <-t.test(new_data$TFF1 ~ new_data$has_cancer)
t6 <-t.test(new_data$REG1A ~ new_data$has_cancer)
```

| Variable   | p-value        | Significant |
|------------|----------------|-------------|
| Age        | `r t1$p.value` | yes         |
| Creatinine | `r t2$p.value` | no          |
| LYVE1      | `r t3$p.value` | yes         |
| REG1B      | `r t4$p.value` | yes         |
| TFF1       | `r t5$p.value` | yes         |
| REG1A      | `r t6$p.value` | yes         |

: T-test results and interpretation

No p-value except Creatinine seems to be small enough to not be statistically significant. We will expect to see this in the model.

## Output

Having explored the data and expanded the understanding of the variables to exploit them for machine learning and exterminating unhelpful variables from the data, it's time to write the data away to an Attribute Relation File Format (arff) and to train machine learning models on it.

```{r finalization of data}
write.arff(new_data, "Data/data.arff")
```

# Machine learning

## Algorithm selection

After using the weka Experimenter trying out different algorithms the following results where produced.

```{r ml algorithms comparison}
algores <- read.delim("Data/algores.csv", sep = ",")
kable(algores, caption = "Preformance of diferent algorithms", align = "lcccccccr", booktabs = T) %>%
  kable_styling(latex_options = c("scale_down", "HOLD_position"))
```

*note: that the OneR, J48 and IBk algorithms have been optimised beforehand.*

The model using the SimpleLogistic algorithm is the most accurate, has the biggest area under the curve, and ranks second best in another important category: true positive rate. Thus the SimpleLogistic model will be used.
